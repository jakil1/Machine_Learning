import os
import hashlib
import shutil


def calculate_md5(file_path):
    """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
    hash_md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None


def find_exact_duplicates_by_md5(train_dir, val_dir):
    """ä½¿ç”¨MD5æ‰¾åˆ°å®Œå…¨ç›¸åŒçš„æ–‡ä»¶"""
    train_md5 = {}
    val_md5 = {}

    print("Calculating MD5 for training images...")
    train_count = 0
    for root, dirs, files in os.walk(train_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                path = os.path.join(root, file)
                md5_val = calculate_md5(path)
                if md5_val:
                    train_md5[md5_val] = path
                train_count += 1
                if train_count % 100 == 0:
                    print(f"Processed {train_count} training images...")

    print("Calculating MD5 for validation images...")
    val_count = 0
    for root, dirs, files in os.walk(val_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                path = os.path.join(root, file)
                md5_val = calculate_md5(path)
                if md5_val:
                    val_md5[md5_val] = path
                val_count += 1
                if val_count % 100 == 0:
                    print(f"Processed {val_count} validation images...")

    # æ‰¾åˆ°MD5ç›¸åŒçš„æ–‡ä»¶
    train_md5_set = set(train_md5.keys())
    val_md5_set = set(val_md5.keys())
    exact_duplicates_md5 = train_md5_set.intersection(val_md5_set)

    exact_duplicates = [val_md5[md5] for md5 in exact_duplicates_md5]

    print(f"\n=== MD5 Exact Duplicate Analysis ===")
    print(f"Training images: {len(train_md5)}")
    print(f"Validation images: {len(val_md5)}")
    print(f"Exact duplicates (MD5 match): {len(exact_duplicates)}")

    return exact_duplicates


def create_md5_clean_validation_set(train_dir, val_dir, output_dir):
    """åŸºäºMD5åˆ›å»ºå¹²å‡€çš„éªŒè¯é›†"""

    print("Starting MD5-based validation set cleanup...")

    # æ‰¾åˆ°å®Œå…¨ç›¸åŒçš„æ–‡ä»¶
    exact_duplicates = find_exact_duplicates_by_md5(train_dir, val_dir)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # å¤åˆ¶éé‡å¤çš„å›¾åƒ
    copied_count = 0
    removed_count = 0

    print("Creating clean validation set...")
    for root, dirs, files in os.walk(val_dir):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                source_path = os.path.join(root, file)

                # å¦‚æœè¿™ä¸ªå›¾åƒä¸åœ¨å®Œå…¨é‡å¤åˆ—è¡¨ä¸­ï¼Œå°±å¤åˆ¶å®ƒ
                if source_path not in exact_duplicates:
                    dest_path = os.path.join(output_dir, file)
                    shutil.copy2(source_path, dest_path)
                    copied_count += 1
                else:
                    removed_count += 1

    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(output_dir, "md5_cleaning_report.txt")
    with open(report_path, "w") as f:
        f.write("MD5-BASED VALIDATION SET CLEANING REPORT\n")
        f.write("=" * 50 + "\n")
        f.write(f"Exact duplicates removed: {removed_count}\n")
        f.write(f"Remaining images in clean set: {copied_count}\n\n")

        f.write("EXACT DUPLICATES REMOVED (MD5 match):\n")
        f.write("-" * 40 + "\n")
        for dup in exact_duplicates:
            f.write(f"{dup}\n")

    print(f"\nâœ… MD5-based clean validation set created in: {output_dir}")
    print(f"ğŸ“Š Removed {removed_count} exact duplicates, kept {copied_count} images")
    print(f"ğŸ“„ Detailed report: {report_path}")

    return copied_count, removed_count


def manual_check_specific_pairs(pairs_to_check):
    """æ‰‹åŠ¨æ£€æŸ¥ç‰¹å®šçš„å›¾åƒå¯¹"""
    print("\n=== MANUAL CHECK FOR SPECIFIC PAIRS ===")

    for i, (train_path, val_path) in enumerate(pairs_to_check):
        if os.path.exists(train_path) and os.path.exists(val_path):
            # è®¡ç®—MD5
            train_md5 = calculate_md5(train_path)
            val_md5 = calculate_md5(val_path)

            # è·å–æ–‡ä»¶å¤§å°
            train_size = os.path.getsize(train_path)
            val_size = os.path.getsize(val_path)

            print(f"\nPair {i + 1}:")
            print(f"Train: {os.path.basename(train_path)} (Size: {train_size} bytes, MD5: {train_md5})")
            print(f"Val:   {os.path.basename(val_path)} (Size: {val_size} bytes, MD5: {val_md5})")

            if train_md5 == val_md5:
                print("âœ… EXACT DUPLICATE (MD5 match)")
            else:
                print("âŒ DIFFERENT FILES (MD5 differ)")
        else:
            print(f"âŒ File not found: {train_path} or {val_path}")


def main():
    """ä¸»å‡½æ•°"""
    train_dir = r"F:\Trackdata\images\train"
    val_dir = r"F:\Trackdata\images\val"
    clean_val_dir = r"F:\Trackdata\images\val_clean_md5"

    print("Starting MD5-based exact duplicate removal...")
    print(f"Train directory: {train_dir}")
    print(f"Val directory: {val_dir}")
    print(f"Clean val directory: {clean_val_dir}")
    print("-" * 50)

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(train_dir):
        print(f"âŒ Error: Train directory does not exist: {train_dir}")
        return

    if not os.path.exists(val_dir):
        print(f"âŒ Error: Val directory does not exist: {val_dir}")
        return

    # åˆ›å»ºåŸºäºMD5çš„å¹²å‡€éªŒè¯é›†
    copied, removed = create_md5_clean_validation_set(train_dir, val_dir, clean_val_dir)

    print("\n" + "=" * 50)
    print("ğŸ¯ MD5 CLEANUP COMPLETED")
    print("=" * 50)
    print(f"âœ… Created clean validation set with {copied} images")
    print(f"âŒ Removed {removed} EXACT duplicates (MD5 match)")
    print(f"ğŸ“ Clean validation set: {clean_val_dir}")

    # æ‰‹åŠ¨æ£€æŸ¥ä¸€äº›ç‰¹å®šçš„å¯¹ï¼ˆä»ä½ çš„åˆ—è¡¨ä¸­é€‰å–ï¼‰
    print("\n" + "=" * 50)
    print("MANUAL VERIFICATION OF SPECIFIC PAIRS")
    print("=" * 50)

    pairs_to_check = [
        (r"F:\Trackdata\images\train\9_5_0.jpg", r"F:\Trackdata\images\val\9_5_0.jpg"),
        (r"F:\Trackdata\images\train\6_3_15.jpg", r"F:\Trackdata\images\val\6_3_15.jpg"),
        (r"F:\Trackdata\images\train\cattle150.jpg", r"F:\Trackdata\images\val\cattle151.jpg"),
        (r"F:\Trackdata\images\train\cattle680.jpg", r"F:\Trackdata\images\val\cattle1800.jpg"),
    ]

    manual_check_specific_pairs(pairs_to_check)

    print("\nNext steps:")
    print("1. Use the new clean validation set for model evaluation")
    print("2. Compare the results with previous evaluations")
    print("3. If accuracy is still suspiciously high, consider visual similarity issues")


if __name__ == "__main__":
    main()